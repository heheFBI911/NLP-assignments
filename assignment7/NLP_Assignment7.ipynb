{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czdtKomPni2J",
        "outputId": "f7d7b411-2408-41e7-cd51-9b250cead592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edHMvjVVrAoS",
        "outputId": "0fd65b25-57f9-4374-87da-da544c8d0a4f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Preprocess the Text Data\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove punctuation and special characters\n",
        "    words = word_tokenize(text)  # Tokenize words\n",
        "    return words"
      ],
      "metadata": {
        "id": "TwRoxxEDqvmI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample corpus (Use a larger dataset for better accuracy)\n",
        "corpus = \"\"\"\n",
        "Artificial intelligence is revolutionizing the world.\n",
        "AI is being used in speech recognition, translation, and automation.\n",
        "Machine learning models are improving every day.\n",
        "AI applications include healthcare, robotics, and smart assistants.\n",
        "\"\"\"\n",
        "\n",
        "words = preprocess_text(corpus)"
      ],
      "metadata": {
        "id": "7U7dbvS3qy9H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Build the N-gram Model\n",
        "def build_ngram_model(words, n=2):\n",
        "    ngram_counts = defaultdict(Counter)\n",
        "\n",
        "    # Create N-grams\n",
        "    n_grams = list(ngrams(words, n))\n",
        "\n",
        "    for gram in n_grams:\n",
        "        prefix = gram[:-1]  # First (n-1) words\n",
        "        next_word = gram[-1]  # Last word\n",
        "        ngram_counts[prefix][next_word] += 1  # Count occurrences\n",
        "\n",
        "    # Convert counts to probabilities\n",
        "    ngram_probabilities = {prefix: {word: count / sum(counts.values())\n",
        "                                    for word, count in counts.items()}\n",
        "                           for prefix, counts in ngram_counts.items()}\n",
        "\n",
        "    return ngram_probabilities"
      ],
      "metadata": {
        "id": "DubxWTR9rDht"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build bigram and trigram models\n",
        "bigram_model = build_ngram_model(words, 2)\n",
        "trigram_model = build_ngram_model(words, 3)"
      ],
      "metadata": {
        "id": "Q_5XAYNKrINB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Predict the Next Word\n",
        "def predict_next_word(previous_words, ngram_model):\n",
        "    previous_words = tuple(previous_words)\n",
        "\n",
        "    if previous_words in ngram_model:\n",
        "        word_probabilities = ngram_model[previous_words]\n",
        "        return max(word_probabilities, key=word_probabilities.get)  # Most probable word\n",
        "\n",
        "    return None  # No prediction available"
      ],
      "metadata": {
        "id": "-qdBZHVVrdKA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Auto-Complete Function\n",
        "def auto_complete(text, ngram_model):\n",
        "    text = preprocess_text(text)\n",
        "\n",
        "    if len(text) >= 2:\n",
        "        # Use trigrams if we have at least 2 previous words\n",
        "        predicted_word = predict_next_word(text[-2:], trigram_model)\n",
        "        if predicted_word:\n",
        "            return predicted_word\n",
        "\n",
        "    if len(text) >= 1:\n",
        "        # Use bigrams if we have at least 1 previous word\n",
        "        predicted_word = predict_next_word(text[-1:], bigram_model)\n",
        "        if predicted_word:\n",
        "            return predicted_word\n",
        "\n",
        "    return \"No suggestion\""
      ],
      "metadata": {
        "id": "EOPRWf_OrhKD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Test the Model\n",
        "user_input = \"computer science and \"\n",
        "predicted_word = auto_complete(user_input, bigram_model)\n",
        "print(f\"Predicted next word: {predicted_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_Kg1474rk4_",
        "outputId": "46ddec55-acf0-4f5d-e274-4975bda25a8d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next word: automation\n"
          ]
        }
      ]
    }
  ]
}